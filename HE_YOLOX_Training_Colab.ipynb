{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca7b3aa",
   "metadata": {},
   "source": [
    "## ðŸ“‹ Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b474c36",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ HE-YOLOX-ASFF Training Notebook\n",
    "\n",
    "### Quick Recovery After Disconnection:\n",
    "If your Colab session disconnected, run the **Quick Recovery** cell below to resume training instantly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ðŸš€ QUICK RECOVERY CELL - Run this after disconnection to resume training!\n",
    "# This single cell does EVERYTHING needed to continue from where you left off\n",
    "\n",
    "print(\"ðŸ”„ Quick Recovery Mode - Resuming Training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Mount Google Drive (for dataset and checkpoints)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. Install dependencies\n",
    "!pip install -q pyyaml tensorboard thop albumentations pycocotools\n",
    "\n",
    "# 3. Clone code from GitHub (fresh copy each time)\n",
    "import os\n",
    "GITHUB_REPO = \"https://github.com/habibour/target_detection_paper.git\"\n",
    "\n",
    "if os.path.exists('/content/code'):\n",
    "    !rm -rf /content/code\n",
    "    \n",
    "print(\"ðŸ“¥ Cloning code from GitHub...\")\n",
    "!git clone {GITHUB_REPO} /content/code\n",
    "\n",
    "# Navigate to implement folder\n",
    "if os.path.exists('/content/code/implement'):\n",
    "    os.chdir('/content/code/implement')\n",
    "else:\n",
    "    os.chdir('/content/code')\n",
    "print(f\"âœ… Working directory: {os.getcwd()}\")\n",
    "\n",
    "# 4. Setup paths\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "\n",
    "# 5. Setup dataset links\n",
    "!mkdir -p data/VisDrone2019\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-train\" data/VisDrone2019/VisDrone2019-DET-train\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-val\" data/VisDrone2019/VisDrone2019-DET-val\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-test-dev\" data/VisDrone2019/VisDrone2019-DET-test-dev\n",
    "\n",
    "# 6. Create colab config\n",
    "import yaml\n",
    "config_path = 'configs/he_yolox_asff.yaml'\n",
    "if os.path.exists(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    config['data']['data_dir'] = './data/VisDrone2019'\n",
    "    config['output']['model_dir'] = CHECKPOINT_DIR\n",
    "    config['output']['log_dir'] = f\"{PROJECT_DIR}/HE_YOLOX_logs\"\n",
    "    config['output']['results_dir'] = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "    config['train']['batch_size'] = 16\n",
    "    config['train']['save_interval'] = 5\n",
    "    with open('configs/he_yolox_asff_colab.yaml', 'w') as f:\n",
    "        yaml.dump(config, f)\n",
    "\n",
    "# 7. Find latest checkpoint and resume\n",
    "import glob\n",
    "import re\n",
    "\n",
    "checkpoints = glob.glob(f\"{CHECKPOINT_DIR}/epoch_*.pth\")\n",
    "if checkpoints:\n",
    "    epoch_nums = []\n",
    "    for ckpt in checkpoints:\n",
    "        match = re.search(r'epoch_(\\d+)\\.pth', ckpt)\n",
    "        if match:\n",
    "            epoch_nums.append((int(match.group(1)), ckpt))\n",
    "    if epoch_nums:\n",
    "        epoch_nums.sort(key=lambda x: x[0], reverse=True)\n",
    "        last_epoch, latest_ckpt = epoch_nums[0]\n",
    "        print(f\"\\nâœ… Found checkpoint at epoch {last_epoch}\")\n",
    "        print(f\"   Remaining epochs: {300 - last_epoch}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"ðŸš€ Resuming training...\")\n",
    "        print(\"=\"*60)\n",
    "        !python train.py \\\n",
    "            --config configs/he_yolox_asff_colab.yaml \\\n",
    "            --device cuda \\\n",
    "            --epochs 300 \\\n",
    "            --resume {latest_ckpt}\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ No valid checkpoints found. Run the step-by-step cells for first-time setup.\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ No checkpoint found. This appears to be a fresh start.\")\n",
    "    print(\"   Run the step-by-step cells below for first-time setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pyyaml tensorboard thop albumentations pycocotools\n",
    "\n",
    "print(\"âœ… Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8263e2",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 2: Mount Google Drive (for checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Project paths on Google Drive\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "LOG_DIR = f\"{PROJECT_DIR}/HE_YOLOX_logs\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "# Create directories for checkpoints, logs, and results\n",
    "!mkdir -p \"{CHECKPOINT_DIR}\"\n",
    "!mkdir -p \"{LOG_DIR}\"\n",
    "!mkdir -p \"{RESULTS_DIR}\"\n",
    "\n",
    "# Verify dataset exists\n",
    "import os\n",
    "dataset_paths = {\n",
    "    'train': f\"{PROJECT_DIR}/VisDrone2019-DET-train\",\n",
    "    'val': f\"{PROJECT_DIR}/VisDrone2019-DET-val\",\n",
    "    'test_dev': f\"{PROJECT_DIR}/VisDrone2019-DET-test-dev\",\n",
    "    'test_challenge': f\"{PROJECT_DIR}/VisDrone2019-DET-test-challenge\"\n",
    "}\n",
    "\n",
    "print(\"ðŸ“Š Checking dataset availability:\")\n",
    "for split, path in dataset_paths.items():\n",
    "    if os.path.exists(path):\n",
    "        images_path = os.path.join(path, 'images')\n",
    "        if os.path.exists(images_path):\n",
    "            num_images = len(os.listdir(images_path))\n",
    "            print(f\"  âœ… {split}: {num_images} images found\")\n",
    "        else:\n",
    "            print(f\"  âš ï¸ {split}: folder exists but no 'images' subfolder\")\n",
    "    else:\n",
    "        print(f\"  âŒ {split}: NOT FOUND at {path}\")\n",
    "\n",
    "print(\"\\nâœ… Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d75418",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Step 3: Clone Code from GitHub\n",
    "\n",
    "Code is cloned fresh each session to `/content/code` (Colab's local storage).\n",
    "- **Dataset & Checkpoints**: Stored on Google Drive (persistent)\n",
    "- **Code**: From GitHub (always latest version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93129de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone code from GitHub (to /content - fresh each session)\n",
    "import os\n",
    "\n",
    "GITHUB_REPO = \"https://github.com/habibour/target_detection_paper.git\"\n",
    "\n",
    "# Remove old code if exists and clone fresh\n",
    "if os.path.exists('/content/code'):\n",
    "    print(\"ðŸ—‘ï¸ Removing old code...\")\n",
    "    !rm -rf /content/code\n",
    "\n",
    "print(\"ðŸ“¥ Cloning code from GitHub...\")\n",
    "!git clone {GITHUB_REPO} /content/code\n",
    "\n",
    "# Navigate to the implement folder\n",
    "if os.path.exists('/content/code/implement'):\n",
    "    os.chdir('/content/code/implement')\n",
    "    print(f\"\\nðŸ“ Working directory: {os.getcwd()}\")\n",
    "else:\n",
    "    os.chdir('/content/code')\n",
    "    print(f\"\\nðŸ“ Working directory: {os.getcwd()}\")\n",
    "\n",
    "!ls -la\n",
    "print(\"\\nâœ… Code is ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Upload ZIP file (if not using GitHub)\n",
    "# Uncomment and run this cell only if you prefer manual upload\n",
    "\n",
    "# from google.colab import files\n",
    "# import zipfile\n",
    "\n",
    "# print(\"ðŸ“¤ Upload your project ZIP file...\")\n",
    "# uploaded = files.upload()\n",
    "\n",
    "# # Extract the ZIP to /content\n",
    "# for filename in uploaded.keys():\n",
    "#     print(f\"Extracting {filename}...\")\n",
    "#     with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "#         zip_ref.extractall('/content')\n",
    "#     print(f\"âœ… Extracted {filename}\")\n",
    "\n",
    "# # Navigate to project directory\n",
    "# %cd /content/implement\n",
    "# !ls -la"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be526e25",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 4: Setup Dataset Paths (Using Existing Data on Drive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Dataset is already on Google Drive - no need to download!\n",
    "# Just create symbolic links for easier access\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "\n",
    "# Create data directory structure\n",
    "!mkdir -p data/VisDrone2019\n",
    "\n",
    "# Create symbolic links to the datasets on Google Drive\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-train\" data/VisDrone2019/VisDrone2019-DET-train\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-val\" data/VisDrone2019/VisDrone2019-DET-val\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-test-dev\" data/VisDrone2019/VisDrone2019-DET-test-dev\n",
    "!ln -sf \"{PROJECT_DIR}/VisDrone2019-DET-test-challenge\" data/VisDrone2019/VisDrone2019-DET-test-challenge\n",
    "\n",
    "# Verify symbolic links\n",
    "print(\"\\nðŸ“Š Dataset Statistics:\")\n",
    "for split in ['train', 'val', 'test-dev', 'test-challenge']:\n",
    "    images_path = f\"data/VisDrone2019/VisDrone2019-DET-{split}/images\"\n",
    "    if os.path.exists(images_path):\n",
    "        num_images = len(os.listdir(images_path))\n",
    "        print(f\"  {split}: {num_images} images\")\n",
    "    else:\n",
    "        print(f\"  {split}: Not found\")\n",
    "\n",
    "print(\"\\nâœ… Dataset paths configured!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555037f",
   "metadata": {},
   "source": [
    "## âš™ï¸ Step 5: Update Configuration for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "LOG_DIR = f\"{PROJECT_DIR}/HE_YOLOX_logs\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "# Load config\n",
    "with open('configs/he_yolox_asff.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths for Colab with Google Drive\n",
    "config['data']['data_dir'] = './data/VisDrone2019'\n",
    "config['output']['model_dir'] = CHECKPOINT_DIR\n",
    "config['output']['log_dir'] = LOG_DIR\n",
    "config['output']['results_dir'] = RESULTS_DIR\n",
    "\n",
    "# Optimize for Colab (adjust batch size based on GPU memory)\n",
    "# T4 GPU has 16GB, can handle batch size 16 for 640x640 images\n",
    "config['train']['batch_size'] = 16\n",
    "config['val']['batch_size'] = 16\n",
    "config['train']['num_workers'] = 2  # Colab has limited CPU cores\n",
    "config['val']['num_workers'] = 2\n",
    "\n",
    "# Enable checkpoint saving every N epochs for recovery\n",
    "config['train']['save_interval'] = 5  # Save every 5 epochs\n",
    "\n",
    "# Save updated config\n",
    "with open('configs/he_yolox_asff_colab.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"âœ… Configuration updated for Colab!\")\n",
    "print(f\"\\nSettings:\")\n",
    "print(f\"  Batch size: {config['train']['batch_size']}\")\n",
    "print(f\"  Checkpoints: {CHECKPOINT_DIR}\")\n",
    "print(f\"  Logs: {LOG_DIR}\")\n",
    "print(f\"  Results: {RESULTS_DIR}\")\n",
    "print(f\"  Save interval: Every 5 epochs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460ede8",
   "metadata": {},
   "source": [
    "## ðŸ§ª Step 6: Test Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9954978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model can be built\n",
    "import torch\n",
    "from models import build_he_yolox\n",
    "\n",
    "print(\"Building HE-YOLOX-S model...\")\n",
    "model = build_he_yolox(\"s\", num_classes=13)\n",
    "model = model.cuda()\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 3, 640, 640).cuda()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(x)\n",
    "\n",
    "print(f\"\\nâœ… Model test passed!\")\n",
    "print(f\"Output shape: {outputs.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal Parameters: {total_params / 1e6:.2f}M\")\n",
    "print(f\"Trainable Parameters: {trainable_params / 1e6:.2f}M\")\n",
    "\n",
    "del model, x\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfbae1",
   "metadata": {},
   "source": [
    "## ðŸš€ Step 7: Start Training (with Auto-Resume)\n",
    "\n",
    "**Important Notes:**\n",
    "- Training will take 12-18 hours on T4 GPU\n",
    "- **Checkpoints are saved every 5 epochs to Google Drive** \n",
    "- **If session disconnects, just re-run this cell - it will automatically resume from the last checkpoint!**\n",
    "- Best model is automatically saved as `best.pth` when validation improves\n",
    "- All weights are safely stored on Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949fe29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš¡ ANTI-DISCONNECT: Run this to prevent Colab from disconnecting due to inactivity\n",
    "# This creates a JavaScript snippet that clicks to keep the session alive\n",
    "\n",
    "from IPython.display import display, Javascript\n",
    "import time\n",
    "\n",
    "def keep_alive():\n",
    "    \"\"\"Display JavaScript to prevent Colab timeout\"\"\"\n",
    "    display(Javascript('''\n",
    "        function ClickConnect(){\n",
    "            console.log(\"Keeping Colab alive...\");\n",
    "            document.querySelector(\"colab-connect-button\").click()\n",
    "        }\n",
    "        setInterval(ClickConnect, 60000)\n",
    "    '''))\n",
    "    print(\"âœ… Anti-disconnect enabled! Session will stay alive.\")\n",
    "\n",
    "# Uncomment the line below to enable (may not work in all cases)\n",
    "# keep_alive()\n",
    "\n",
    "print(\"ðŸ’¡ Tip: To prevent disconnection, you can also:\")\n",
    "print(\"   1. Keep the browser tab active\")\n",
    "print(\"   2. Use Colab Pro for longer runtime\")\n",
    "print(\"   3. Run a simple loop in browser console:\")\n",
    "print(\"      setInterval(() => { console.log('alive'); }, 60000)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b029e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    \"\"\"Find the latest checkpoint to resume from\"\"\"\n",
    "    # Look for epoch checkpoints\n",
    "    epoch_checkpoints = glob.glob(f\"{CHECKPOINT_DIR}/epoch_*.pth\")\n",
    "    \n",
    "    if not epoch_checkpoints:\n",
    "        return None, 0\n",
    "    \n",
    "    # Extract epoch numbers and find the latest\n",
    "    epoch_nums = []\n",
    "    for ckpt in epoch_checkpoints:\n",
    "        match = re.search(r'epoch_(\\d+)\\.pth', ckpt)\n",
    "        if match:\n",
    "            epoch_nums.append((int(match.group(1)), ckpt))\n",
    "    \n",
    "    if epoch_nums:\n",
    "        epoch_nums.sort(key=lambda x: x[0], reverse=True)\n",
    "        return epoch_nums[0][1], epoch_nums[0][0]\n",
    "    \n",
    "    return None, 0\n",
    "\n",
    "# Check for existing checkpoint\n",
    "latest_checkpoint, last_epoch = find_latest_checkpoint()\n",
    "best_checkpoint = f\"{CHECKPOINT_DIR}/best.pth\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ” Checkpoint Status:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if latest_checkpoint:\n",
    "    print(f\"âœ… Found checkpoint: {os.path.basename(latest_checkpoint)}\")\n",
    "    print(f\"   Last completed epoch: {last_epoch}\")\n",
    "    resume_flag = f\"--resume {latest_checkpoint}\"\n",
    "    remaining_epochs = 300 - last_epoch\n",
    "    print(f\"   Remaining epochs: {remaining_epochs}\")\n",
    "else:\n",
    "    print(\"ðŸ“ No checkpoint found. Starting fresh training.\")\n",
    "    resume_flag = \"\"\n",
    "    remaining_epochs = 300\n",
    "\n",
    "if os.path.exists(best_checkpoint):\n",
    "    print(f\"â­ Best model exists at: {os.path.basename(best_checkpoint)}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸš€ Starting training...\")\n",
    "print(f\"   Config: configs/he_yolox_asff_colab.yaml\")\n",
    "print(f\"   Total epochs: 300\")\n",
    "if resume_flag:\n",
    "    print(f\"   Resuming from epoch: {last_epoch + 1}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Start training with auto-resume\n",
    "!python train.py \\\n",
    "    --config configs/he_yolox_asff_colab.yaml \\\n",
    "    --device cuda \\\n",
    "    --epochs 300 \\\n",
    "    {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b801f",
   "metadata": {},
   "source": [
    "## ðŸ“Š Step 8: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell while training to monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/HE_YOLOX/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a75939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ffe21",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ Step 9: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c732aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "# Check which weights to use\n",
    "best_weights = f\"{CHECKPOINT_DIR}/best.pth\"\n",
    "if os.path.exists(best_weights):\n",
    "    weights_path = best_weights\n",
    "    print(f\"âœ… Using best model: {weights_path}\")\n",
    "else:\n",
    "    # Find latest epoch checkpoint\n",
    "    import glob\n",
    "    checkpoints = sorted(glob.glob(f\"{CHECKPOINT_DIR}/epoch_*.pth\"))\n",
    "    if checkpoints:\n",
    "        weights_path = checkpoints[-1]\n",
    "        print(f\"âš ï¸ Best model not found, using latest checkpoint: {weights_path}\")\n",
    "    else:\n",
    "        print(\"âŒ No weights found! Please train the model first.\")\n",
    "        weights_path = None\n",
    "\n",
    "if weights_path:\n",
    "    # Evaluate on validation set\n",
    "    !python eval.py \\\n",
    "        --config configs/he_yolox_asff_colab.yaml \\\n",
    "        --weights {weights_path} \\\n",
    "        --split val \\\n",
    "        --device cuda\n",
    "\n",
    "    # Display results\n",
    "    results_file = f\"{RESULTS_DIR}/eval_results.txt\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ðŸ“Š Evaluation Results:\")\n",
    "    print(\"=\"*60)\n",
    "    if os.path.exists(results_file):\n",
    "        with open(results_file, 'r') as f:\n",
    "            print(f.read())\n",
    "    else:\n",
    "        print(\"Results file not found. Check logs for evaluation output.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e505f2",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Step 10: Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "# Create test directory\n",
    "!mkdir -p test_images\n",
    "\n",
    "# Copy 5 random validation images\n",
    "val_images = glob.glob('data/VisDrone2019/VisDrone2019-DET-val/images/*.jpg')\n",
    "if val_images:\n",
    "    selected_images = random.sample(val_images, min(5, len(val_images)))\n",
    "    for img in selected_images:\n",
    "        shutil.copy(img, 'test_images/')\n",
    "    print(f\"âœ… Selected {len(selected_images)} test images\")\n",
    "else:\n",
    "    print(\"âŒ No validation images found!\")\n",
    "    selected_images = []\n",
    "\n",
    "# Find weights\n",
    "best_weights = f\"{CHECKPOINT_DIR}/best.pth\"\n",
    "if os.path.exists(best_weights):\n",
    "    weights_path = best_weights\n",
    "else:\n",
    "    checkpoints = sorted(glob.glob(f\"{CHECKPOINT_DIR}/epoch_*.pth\"))\n",
    "    weights_path = checkpoints[-1] if checkpoints else None\n",
    "\n",
    "if weights_path and selected_images:\n",
    "    # Run inference\n",
    "    !python inference.py \\\n",
    "        --config configs/he_yolox_asff_colab.yaml \\\n",
    "        --weights {weights_path} \\\n",
    "        --source test_images/ \\\n",
    "        --output {RESULTS_DIR}/inference \\\n",
    "        --conf_thresh 0.3 \\\n",
    "        --save_img \\\n",
    "        --device cuda\n",
    "\n",
    "    print(f\"\\nâœ… Inference complete! Results saved to: {RESULTS_DIR}/inference\")\n",
    "else:\n",
    "    if not weights_path:\n",
    "        print(\"âŒ No trained weights found!\")\n",
    "    if not selected_images:\n",
    "        print(\"âŒ No test images available!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import glob\n",
    "import os\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "# Find result images\n",
    "result_images = glob.glob(f'{RESULTS_DIR}/inference/*.jpg')\n",
    "result_images.extend(glob.glob(f'{RESULTS_DIR}/inference/*.png'))\n",
    "\n",
    "if result_images:\n",
    "    # Display up to 4 results in a 2x2 grid\n",
    "    num_display = min(4, len(result_images))\n",
    "    rows = (num_display + 1) // 2\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, 2, figsize=(16, 8 * rows))\n",
    "    axes = axes.flatten() if num_display > 1 else [axes]\n",
    "    \n",
    "    for idx, img_path in enumerate(result_images[:num_display]):\n",
    "        img = Image.open(img_path)\n",
    "        axes[idx].imshow(img)\n",
    "        axes[idx].axis('off')\n",
    "        axes[idx].set_title(f'Detection Result {idx+1}', fontsize=12)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(num_display, len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Total inference results: {len(result_images)}\")\n",
    "else:\n",
    "    print(\"âŒ No inference results found. Run inference first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975118de",
   "metadata": {},
   "source": [
    "## ðŸ’¾ Step 11: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from google.colab import files\n",
    "\n",
    "PROJECT_DIR = \"/content/drive/MyDrive/paper/target_detection\"\n",
    "CHECKPOINT_DIR = f\"{PROJECT_DIR}/HE_YOLOX_checkpoints\"\n",
    "RESULTS_DIR = f\"{PROJECT_DIR}/HE_YOLOX_results\"\n",
    "\n",
    "print(\"ðŸ“¦ Creating results archive...\")\n",
    "\n",
    "# Create a temporary directory with key files\n",
    "!mkdir -p /content/export_results\n",
    "!cp -r {RESULTS_DIR}/* /content/export_results/ 2>/dev/null || echo \"No results yet\"\n",
    "\n",
    "# Copy best model if exists\n",
    "if os.path.exists(f\"{CHECKPOINT_DIR}/best.pth\"):\n",
    "    !cp {CHECKPOINT_DIR}/best.pth /content/export_results/\n",
    "\n",
    "# Create archive\n",
    "shutil.make_archive('/content/he_yolox_results', 'zip', '/content/export_results')\n",
    "\n",
    "print(\"\\nðŸ“¥ Download starting...\")\n",
    "files.download('/content/he_yolox_results.zip')\n",
    "\n",
    "print(\"\\nâœ… Results downloaded! Contains:\")\n",
    "print(\"  - Best model weights (best.pth)\")  \n",
    "print(\"  - Evaluation results\")\n",
    "print(\"  - Inference visualizations\")\n",
    "print(\"\\nðŸ’¡ Note: All checkpoints remain safely on Google Drive at:\")\n",
    "print(f\"   {CHECKPOINT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1735712",
   "metadata": {},
   "source": [
    "## ðŸ“Š Training Summary\n",
    "\n",
    "### Expected Results (from paper):\n",
    "\n",
    "| Class | Target AP (%) |\n",
    "|-------|---------------|\n",
    "| Car | 81.2 |\n",
    "| Bus | 66.4 |\n",
    "| Truck | 55.6 |\n",
    "| Pedestrian | 42.6 |\n",
    "| Motor | 45.5 |\n",
    "| Bicycle | 19.4 |\n",
    "\n",
    "### Files on Google Drive:\n",
    "```\n",
    "/content/drive/MyDrive/paper/target_detection/\n",
    "â”œâ”€â”€ VisDrone2019-DET-train/          # Training data\n",
    "â”œâ”€â”€ VisDrone2019-DET-val/            # Validation data  \n",
    "â”œâ”€â”€ VisDrone2019-DET-test-dev/       # Test data\n",
    "â”œâ”€â”€ VisDrone2019-DET-test-challenge/ # Challenge test data\n",
    "â”œâ”€â”€ HE_YOLOX_checkpoints/            # Model weights\n",
    "â”‚   â”œâ”€â”€ best.pth                     # Best model\n",
    "â”‚   â””â”€â”€ epoch_*.pth                  # Epoch checkpoints\n",
    "â”œâ”€â”€ HE_YOLOX_logs/                   # TensorBoard logs\n",
    "â””â”€â”€ HE_YOLOX_results/                # Evaluation & inference\n",
    "```\n",
    "\n",
    "### ðŸ”„ Recovery After Disconnection:\n",
    "1. Re-run **Cell 1-4** (GPU check, install deps, mount drive, setup paths)\n",
    "2. Skip to **Cell 7** (Training) - it will automatically resume from last checkpoint!\n",
    "\n",
    "### Tips:\n",
    "1. **Checkpoints saved every 5 epochs** to Google Drive\n",
    "2. **Auto-resume:** Just re-run training cell after disconnection  \n",
    "3. **Best model:** Automatically saved when validation improves\n",
    "4. **Full training:** Takes ~12-18 hours on T4 GPU\n",
    "\n",
    "---\n",
    "\n",
    "**ðŸŽ‰ Congratulations! You've successfully set up HE-YOLOX-ASFF training!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cb66a",
   "metadata": {},
   "source": [
    "## ðŸš€ Next Steps\n",
    "\n",
    "1. **Compare with paper results** - Check if your mAP matches the paper\n",
    "2. **Fine-tune hyperparameters** - Adjust learning rate, batch size\n",
    "3. **Test on custom images** - Upload your own drone images\n",
    "4. **Export model** - Convert to ONNX for deployment\n",
    "5. **Experiment** - Try different model sizes (M, L, X)\n",
    "\n",
    "### Resources:\n",
    "- Paper: DOI 10.1109/ICDSCNC62492.2024.10939462\n",
    "- VisDrone Dataset: http://aiskyeye.com/\n",
    "- Your results: `/content/drive/MyDrive/HE_YOLOX/`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
