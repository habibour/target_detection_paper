{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ca7b3aa",
   "metadata": {},
   "source": [
    "## üìã Step 1: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065cf94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c663f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q pyyaml tensorboard thop albumentations pycocotools\n",
    "\n",
    "print(\"‚úÖ Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8263e2",
   "metadata": {},
   "source": [
    "## üíæ Step 2: Mount Google Drive (for checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Create project directory in Google Drive\n",
    "!mkdir -p \"/content/drive/MyDrive/HE_YOLOX\"\n",
    "!mkdir -p \"/content/drive/MyDrive/HE_YOLOX/checkpoints\"\n",
    "!mkdir -p \"/content/drive/MyDrive/HE_YOLOX/logs\"\n",
    "!mkdir -p \"/content/drive/MyDrive/HE_YOLOX/results\"\n",
    "\n",
    "print(\"‚úÖ Google Drive mounted successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d75418",
   "metadata": {},
   "source": [
    "## üì¶ Step 3: Upload Project Files\n",
    "\n",
    "**Option A: Upload the entire project folder as a ZIP**\n",
    "- Zip your `implement` folder locally\n",
    "- Upload it using the cell below\n",
    "\n",
    "**Option B: Clone from GitHub (if you pushed the code)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93129de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option A: Upload ZIP file\n",
    "from google.colab import files\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "print(\"üì§ Upload your project ZIP file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the ZIP\n",
    "for filename in uploaded.keys():\n",
    "    print(f\"Extracting {filename}...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('/content')\n",
    "    print(f\"‚úÖ Extracted {filename}\")\n",
    "\n",
    "# Navigate to project directory\n",
    "%cd /content/implement\n",
    "!ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bf6ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option B: Clone from GitHub (uncomment if using)\n",
    "# !git clone https://github.com/YOUR_USERNAME/HE-YOLOX-ASFF.git\n",
    "# %cd HE-YOLOX-ASFF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be526e25",
   "metadata": {},
   "source": [
    "## üìä Step 4: Download VisDrone2019 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe2d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Create data directory\n",
    "!mkdir -p data/VisDrone2019\n",
    "\n",
    "# Dataset URLs\n",
    "urls = {\n",
    "    'train': 'https://github.com/VisDrone/VisDrone-Dataset/releases/download/v1.0/VisDrone2019-DET-train.zip',\n",
    "    'val': 'https://github.com/VisDrone/VisDrone-Dataset/releases/download/v1.0/VisDrone2019-DET-val.zip',\n",
    "    'test': 'https://github.com/VisDrone/VisDrone-Dataset/releases/download/v1.0/VisDrone2019-DET-test-dev.zip'\n",
    "}\n",
    "\n",
    "def download_and_extract(url, split_name):\n",
    "    filename = f\"data/VisDrone2019/{split_name}.zip\"\n",
    "    \n",
    "    # Download\n",
    "    print(f\"\\nüì• Downloading {split_name} set...\")\n",
    "    urllib.request.urlretrieve(url, filename)\n",
    "    \n",
    "    # Extract\n",
    "    print(f\"üì¶ Extracting {split_name} set...\")\n",
    "    with zipfile.ZipFile(filename, 'r') as zip_ref:\n",
    "        zip_ref.extractall('data/VisDrone2019')\n",
    "    \n",
    "    # Remove zip file\n",
    "    os.remove(filename)\n",
    "    print(f\"‚úÖ {split_name} set ready!\")\n",
    "\n",
    "# Download all splits\n",
    "for split, url in urls.items():\n",
    "    download_and_extract(url, split)\n",
    "\n",
    "# Verify dataset\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "!echo \"Training images: $(ls data/VisDrone2019/VisDrone2019-DET-train/images | wc -l)\"\n",
    "!echo \"Validation images: $(ls data/VisDrone2019/VisDrone2019-DET-val/images | wc -l)\"\n",
    "!echo \"Test images: $(ls data/VisDrone2019/VisDrone2019-DET-test-dev/images | wc -l)\"\n",
    "\n",
    "print(\"\\n‚úÖ Dataset downloaded and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555037f",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Step 5: Update Configuration for Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eaeb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load config\n",
    "with open('configs/he_yolox_asff.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Update paths for Colab\n",
    "config['data']['data_dir'] = './data/VisDrone2019'\n",
    "config['output']['model_dir'] = '/content/drive/MyDrive/HE_YOLOX/checkpoints'\n",
    "config['output']['log_dir'] = '/content/drive/MyDrive/HE_YOLOX/logs'\n",
    "config['output']['results_dir'] = '/content/drive/MyDrive/HE_YOLOX/results'\n",
    "\n",
    "# Optimize for Colab (adjust batch size based on GPU memory)\n",
    "config['train']['batch_size'] = 16  # T4 can handle 16\n",
    "config['val']['batch_size'] = 16\n",
    "config['train']['num_workers'] = 2  # Colab has limited CPU cores\n",
    "config['val']['num_workers'] = 2\n",
    "\n",
    "# Save updated config\n",
    "with open('configs/he_yolox_asff_colab.yaml', 'w') as f:\n",
    "    yaml.dump(config, f)\n",
    "\n",
    "print(\"‚úÖ Configuration updated for Colab!\")\n",
    "print(f\"\\nBatch size: {config['train']['batch_size']}\")\n",
    "print(f\"Checkpoints will be saved to: {config['output']['model_dir']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f460ede8",
   "metadata": {},
   "source": [
    "## üß™ Step 6: Test Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9954978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test model can be built\n",
    "import torch\n",
    "from models import build_he_yolox\n",
    "\n",
    "print(\"Building HE-YOLOX-S model...\")\n",
    "model = build_he_yolox(\"s\", num_classes=13)\n",
    "model = model.cuda()\n",
    "\n",
    "# Test forward pass\n",
    "x = torch.randn(2, 3, 640, 640).cuda()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(x)\n",
    "\n",
    "print(f\"\\n‚úÖ Model test passed!\")\n",
    "print(f\"Output shape: {outputs.shape}\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nTotal Parameters: {total_params / 1e6:.2f}M\")\n",
    "print(f\"Trainable Parameters: {trainable_params / 1e6:.2f}M\")\n",
    "\n",
    "del model, x\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dfbae1",
   "metadata": {},
   "source": [
    "## üöÄ Step 7: Start Training\n",
    "\n",
    "**Important Notes:**\n",
    "- Training will take 12-18 hours on T4 GPU\n",
    "- Checkpoints are saved every 10 epochs to Google Drive\n",
    "- If session times out, run this cell again with `--resume` flag\n",
    "- Best model is automatically saved when validation loss improves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b029e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for existing checkpoint to resume\n",
    "import os\n",
    "import glob\n",
    "\n",
    "checkpoint_dir = '/content/drive/MyDrive/HE_YOLOX/checkpoints'\n",
    "checkpoints = sorted(glob.glob(f\"{checkpoint_dir}/epoch_*.pth\"))\n",
    "\n",
    "if checkpoints:\n",
    "    latest_checkpoint = checkpoints[-1]\n",
    "    print(f\"Found checkpoint: {latest_checkpoint}\")\n",
    "    print(f\"Resume training? (y/n)\")\n",
    "    resume_flag = f\"--resume {latest_checkpoint}\"\n",
    "else:\n",
    "    print(\"No checkpoint found. Starting fresh training.\")\n",
    "    resume_flag = \"\"\n",
    "\n",
    "# Start training\n",
    "!python train.py \\\n",
    "    --config configs/he_yolox_asff_colab.yaml \\\n",
    "    --device cuda \\\n",
    "    --epochs 300 \\\n",
    "    {resume_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885b801f",
   "metadata": {},
   "source": [
    "## üìä Step 8: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell while training to monitor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcc3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /content/drive/MyDrive/HE_YOLOX/logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a75939",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monitor GPU usage\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ffe21",
   "metadata": {},
   "source": [
    "## üìà Step 9: Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c732aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate best model on validation set\n",
    "!python eval.py \\\n",
    "    --config configs/he_yolox_asff_colab.yaml \\\n",
    "    --weights /content/drive/MyDrive/HE_YOLOX/checkpoints/best.pth \\\n",
    "    --split val \\\n",
    "    --device cuda\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Evaluation Results:\")\n",
    "print(\"=\"*50)\n",
    "!cat /content/drive/MyDrive/HE_YOLOX/results/eval_results.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e505f2",
   "metadata": {},
   "source": [
    "## üéØ Step 10: Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on a few validation images\n",
    "import glob\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Create test directory\n",
    "!mkdir -p test_images\n",
    "\n",
    "# Copy 5 random validation images\n",
    "val_images = glob.glob('data/VisDrone2019/VisDrone2019-DET-val/images/*.jpg')[:5]\n",
    "for img in val_images:\n",
    "    shutil.copy(img, 'test_images/')\n",
    "\n",
    "print(f\"Selected {len(val_images)} test images\")\n",
    "\n",
    "# Run inference\n",
    "!python inference.py \\\n",
    "    --config configs/he_yolox_asff_colab.yaml \\\n",
    "    --weights /content/drive/MyDrive/HE_YOLOX/checkpoints/best.pth \\\n",
    "    --source test_images/ \\\n",
    "    --output /content/drive/MyDrive/HE_YOLOX/results/inference \\\n",
    "    --conf_thresh 0.3 \\\n",
    "    --save_img \\\n",
    "    --device cuda\n",
    "\n",
    "print(\"\\n‚úÖ Inference complete! Check results in Google Drive.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5390d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display inference results\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "result_images = glob.glob('/content/drive/MyDrive/HE_YOLOX/results/inference/*.jpg')\n",
    "\n",
    "# Display first 3 results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "for idx, img_path in enumerate(result_images[:3]):\n",
    "    img = Image.open(img_path)\n",
    "    axes[idx].imshow(img)\n",
    "    axes[idx].axis('off')\n",
    "    axes[idx].set_title(f'Detection Result {idx+1}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTotal results: {len(result_images)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975118de",
   "metadata": {},
   "source": [
    "## üíæ Step 11: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8615a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ZIP of all results\n",
    "import shutil\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì¶ Creating results archive...\")\n",
    "shutil.make_archive('he_yolox_results', 'zip', '/content/drive/MyDrive/HE_YOLOX')\n",
    "\n",
    "print(\"\\nüì• Download starting...\")\n",
    "files.download('he_yolox_results.zip')\n",
    "\n",
    "print(\"\\n‚úÖ Results downloaded! Contains:\")\n",
    "print(\"  - Trained model weights (best.pth)\")\n",
    "print(\"  - All epoch checkpoints\")\n",
    "print(\"  - TensorBoard logs\")\n",
    "print(\"  - Evaluation results\")\n",
    "print(\"  - Inference visualizations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1735712",
   "metadata": {},
   "source": [
    "## üìä Training Summary\n",
    "\n",
    "### Expected Results (from paper):\n",
    "\n",
    "| Class | Target AP (%) |\n",
    "|-------|---------------|\n",
    "| Car | 81.2 |\n",
    "| Bus | 66.4 |\n",
    "| Truck | 55.6 |\n",
    "| Pedestrian | 42.6 |\n",
    "| Motor | 45.5 |\n",
    "| Bicycle | 19.4 |\n",
    "\n",
    "### Files in Google Drive:\n",
    "- `/content/drive/MyDrive/HE_YOLOX/checkpoints/` - Model weights\n",
    "- `/content/drive/MyDrive/HE_YOLOX/logs/` - Training logs\n",
    "- `/content/drive/MyDrive/HE_YOLOX/results/` - Evaluation & inference results\n",
    "\n",
    "### Tips:\n",
    "1. **If session times out:** Just re-run the training cell - it will automatically resume\n",
    "2. **Monitor progress:** Use TensorBoard or check checkpoint files\n",
    "3. **Best model:** Automatically saved as `best.pth` when validation improves\n",
    "4. **Full training:** Takes ~12-18 hours on T4 GPU\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ Congratulations! You've successfully trained HE-YOLOX-ASFF!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641cb66a",
   "metadata": {},
   "source": [
    "## üöÄ Next Steps\n",
    "\n",
    "1. **Compare with paper results** - Check if your mAP matches the paper\n",
    "2. **Fine-tune hyperparameters** - Adjust learning rate, batch size\n",
    "3. **Test on custom images** - Upload your own drone images\n",
    "4. **Export model** - Convert to ONNX for deployment\n",
    "5. **Experiment** - Try different model sizes (M, L, X)\n",
    "\n",
    "### Resources:\n",
    "- Paper: DOI 10.1109/ICDSCNC62492.2024.10939462\n",
    "- VisDrone Dataset: http://aiskyeye.com/\n",
    "- Your results: `/content/drive/MyDrive/HE_YOLOX/`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
